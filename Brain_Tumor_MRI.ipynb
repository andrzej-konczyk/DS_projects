{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ctypes\n",
    "\n",
    "def run_as_admin():\n",
    "    if sys.platform.startswith('win'):\n",
    "        app_dir = os.path.dirname(os.path.realpath(sys.argv[0]))\n",
    "        cmd_args = sys.argv[:]\n",
    "        cmd_args.insert(0, sys.executable)\n",
    "        cmd_args = ['\"{}\"'.format(arg) for arg in cmd_args]\n",
    "        cmd = '{} -m {}'.format(sys.executable, ' '.join(cmd_args))\n",
    "        ctypes.windll.shell32.ShellExecuteW(None, \"runas\", cmd, None, app_dir, 1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_as_admin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data folder\n",
    "data_dir = os.path.join(os.getcwd(), 'Brain Tumor MRI')\n",
    "\n",
    "# Path to processed data\n",
    "output_dir = os.path.join(os.getcwd(), 'Processed Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if folder was created\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration by data in folder\n",
    "for dir_name in os.listdir(data_dir):\n",
    "    # Create path to folder with images\n",
    "    dir_path = os.path.join(data_dir, dir_name)\n",
    "    #Check if item is folder or hidden file\n",
    "    if os.path.isdir(dir_path) and not dir_name.startswith(\".\"):\n",
    "        print(f\"Processing images in {dir_name}...\")\n",
    "        #Create path to output directory for such type of images\n",
    "        output_path = os.path.join(output_dir, dir_name)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        # Iteration by files in folder\n",
    "        for filename in os.listdir(dir_path):\n",
    "            # Check if file is mage\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "                # Load file, initial processing\n",
    "                img_path = os.path.join(dir_path, filename)\n",
    "                with Image.open(img_path) as img:\n",
    "                    img = img.rotate(90)\n",
    "                    # Save processed image\n",
    "                    output_filename = os.path.join(output_path, filename)\n",
    "                    img.save(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data dimensions\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "\n",
    "# Initial pre processing\n",
    "for folder_name in os.listdir(data_dir):\n",
    "    folder_path = os.path.join(data_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f'Preprocessing of {folder_name}')\n",
    "        output_folder_path = os.path.join(output_dir, folder_name)\n",
    "        if not os.path.exists(output_folder_path):\n",
    "            os.makedirs(output_folder_path)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.jpg'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                img = img / 255.0\n",
    "                output_file_path = os.path.join(output_folder_path, file_name)\n",
    "                cv2.imwrite(output_file_path, img * 255.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Processed Data\n",
    "processed_data_path = os.path.join(os.getcwd(), 'Processed Data')\n",
    "\n",
    "# Paths to train/test and validation sets\n",
    "train_path = os.path.join(processed_data_path, \"train\")\n",
    "val_path = os.path.join(processed_data_path, \"validation\")\n",
    "test_path = os.path.join(processed_data_path, \"test\")\n",
    "\n",
    "# Split for train/ test and validation sets\n",
    "train_split = 0.6\n",
    "test_split = 0.2\n",
    "val_split = 0.2\n",
    "\n",
    "# Train, test, validation for paths in processed data\n",
    "for folder_name in os.listdir(processed_data_path):\n",
    "    folder_path = os.path.join(processed_data_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        train_folder_path = os.path.join(train_path, folder_name)\n",
    "        val_folder_path = os.path.join(val_path, folder_name)\n",
    "        test_folder_path = os.path.join(test_path, folder_name)\n",
    "        os.makedirs(train_folder_path, exist_ok=True)\n",
    "        os.makedirs(val_folder_path, exist_ok=True)\n",
    "        os.makedirs(test_folder_path, exist_ok=True)\n",
    "        \n",
    "        # List of files and random order\n",
    "        files = os.listdir(folder_path)\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        \n",
    "        train_files = files[:int(train_split * len(files))]\n",
    "        val_files = files[int(train_split * len(files)):int((train_split + val_split) * len(files))]\n",
    "        test_files = files[int((train_split + val_split) * len(files)):]\n",
    "        for file_name in train_files:\n",
    "            src_path = os.path.join(folder_path, file_name)\n",
    "            dst_path = os.path.join(train_folder_path, file_name)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "        for file_name in val_files:\n",
    "            src_path = os.path.join(folder_path, file_name)\n",
    "            dst_path = os.path.join(val_folder_path, file_name)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "        for file_name in test_files:\n",
    "            src_path = os.path.join(folder_path, file_name)\n",
    "            dst_path = os.path.join(test_folder_path, file_name)\n",
    "            shutil.copy(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data check\n",
    "train_path = os.path.join(\"Processed Data\", \"train\")\n",
    "\n",
    "# \n",
    "classes = []\n",
    "num_images = []\n",
    "dimensions = []\n",
    "pixel_means = []\n",
    "\n",
    "\n",
    "for class_name in os.listdir(train_path):\n",
    "    class_path = os.path.join(train_path, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        classes.append(class_name)\n",
    "        \n",
    "        class_num_images = 0\n",
    "        \n",
    "        class_dimensions = []\n",
    "        \n",
    "        class_pixel_means = []\n",
    "        \n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            if os.path.isfile(image_path):\n",
    "                image = plt.imread(image_path)\n",
    "                height, width = image.shape[:2]\n",
    "                class_dimensions.append((height, width))\n",
    "                \n",
    "                pixel_mean = image.mean()\n",
    "                class_pixel_means.append(pixel_mean)\n",
    "                \n",
    "                class_num_images += 1\n",
    "        \n",
    "        num_images.append(class_num_images)\n",
    "        \n",
    "        class_avg_height = sum([dim[0] for dim in class_dimensions]) / class_num_images\n",
    "        class_avg_width = sum([dim[1] for dim in class_dimensions]) / class_num_images\n",
    "        class_avg_dimension = (class_avg_height, class_avg_width)\n",
    "        dimensions.append(class_avg_dimension)\n",
    "        \n",
    "        class_avg_pixel_mean = sum(class_pixel_means) / class_num_images\n",
    "        pixel_means.append(class_avg_pixel_mean)\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"Class {i + 1}: {class_name}\")\n",
    "    print(f\"Number of images: {num_images[i]}\")\n",
    "    print(f\"Average dimensions: {dimensions[i]}\")\n",
    "    print(f\"Average pixel mean: {pixel_means[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart creation\n",
    "fig, ax = plt.subplots(figsize=(24, 16))\n",
    "ax.bar(classes, num_images, width=0.5)\n",
    "\n",
    "# Labels\n",
    "ax.set_ylabel('Mean no. of images', fontsize=14)\n",
    "ax.set_title('Mean number of images per class in training set', fontsize=16)\n",
    "\n",
    "# Axis details\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "\n",
    "# Font\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Chart show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart creation\n",
    "fig, ax = plt.subplots(figsize=(24, 16))\n",
    "ax.bar(classes, num_images, width=0.5)\n",
    "\n",
    "# Labels\n",
    "ax.set_ylabel('Mean no. of images', fontsize=14)\n",
    "ax.set_title('Mean number of images per class in training set', fontsize=16)\n",
    "\n",
    "# Axis details\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "\n",
    "# Font\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Chart show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuple unpacking\n",
    "x = range(len(classes))\n",
    "y1 = [t[0] for t in dimensions]  # wymiar x\n",
    "y2 = [t[1] for t in dimensions]  # wymiar y\n",
    "\n",
    "# Chart creation\n",
    "fig, ax = plt.subplots(figsize=(24, 16))\n",
    "ax.bar(x, y1, width=0.4, align='center', label='Wymiar x')\n",
    "ax.bar([i+0.4 for i in x], y2, width=0.4, align='center', label='Wymiar y')\n",
    "\n",
    "# Axis details\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "\n",
    "# Title and lables\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_ylabel('Average dimensions', fontsize=14)\n",
    "ax.set_title('Avergae dimensions per class', fontsize=16)\n",
    "ax.legend()\n",
    "\n",
    "# Font\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {class_name: str(i) for i, class_name in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ustaw ścieżkę do katalogu z obrazami\n",
    "train_path = os.path.join(\"Processed Data\", \"train\")\n",
    "\n",
    "# utwórz pustą tablicę X_train i listę y_train\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# przejdź przez katalog i wczytaj każdy obraz\n",
    "for root, dirs, files in os.walk(train_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png') or filename.endswith('.bmp'):\n",
    "            # wczytaj obraz i przetwórz go\n",
    "            img = cv2.imread(os.path.join(root, filename))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (224, 224)) # przykładowy rozmiar\n",
    "            X_train.append(img)\n",
    "\n",
    "            # wczytaj etykietę z nazwy katalogu i dodaj do listy y_train\n",
    "            label = class_dict[root.split(os.path.sep)[-1]]\n",
    "            y_train.append(label)\n",
    "\n",
    "# przekształć listy w tablice numpy\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5755411255411256,\n",
       " 1: 0.43476128188358404,\n",
       " 2: 0.5924688057040999,\n",
       " 3: 1.5495337995337994,\n",
       " 4: 0.915633608815427,\n",
       " 5: 1.4053911205073997,\n",
       " 6: 2.2382154882154883,\n",
       " 7: 2.158279220779221,\n",
       " 8: 1.7774064171122994,\n",
       " 9: 5.035984848484849,\n",
       " 10: 6.043181818181818,\n",
       " 11: 4.648601398601398,\n",
       " 12: 3.7769886363636362,\n",
       " 13: 2.8777056277056277,\n",
       " 14: 3.7769886363636362,\n",
       " 15: 1.831267217630854,\n",
       " 16: 1.0791396103896105,\n",
       " 17: 1.831267217630854,\n",
       " 18: 3.3573232323232323,\n",
       " 19: 3.3573232323232323,\n",
       " 20: 6.043181818181818,\n",
       " 21: 4.648601398601398,\n",
       " 22: 1.5107954545454545,\n",
       " 23: 2.5179924242424243,\n",
       " 24: 0.3707473508087005,\n",
       " 25: 0.27344714109419993,\n",
       " 26: 0.43476128188358404,\n",
       " 27: 0.7747668997668997,\n",
       " 28: 0.45437457279562543,\n",
       " 29: 0.9747067448680352,\n",
       " 30: 1.1849376114081998,\n",
       " 31: 1.4053911205073997,\n",
       " 32: 1.5495337995337994,\n",
       " 33: 1.5495337995337994,\n",
       " 34: 0.9442471590909091,\n",
       " 35: 1.6332923832923834,\n",
       " 36: 0.6867252066115702,\n",
       " 37: 0.5209639498432602,\n",
       " 38: 0.8278331257783312,\n",
       " 39: 3.7769886363636362,\n",
       " 40: 1.2086363636363637,\n",
       " 41: 3.180622009569378,\n",
       " 42: 0.4028787878787879,\n",
       " 43: 0.37303591470258135}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(y_train),\n",
    "                                        y = y_train                                                   \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "class_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5be42bdc0f3942fe006c6eed7ae26cb7bae447fc8643a580b87df87dd2180d23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
